{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "The 5 Step Life-Cycle for LSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkAyc0d_UAPE"
      },
      "source": [
        "Deep learning neural networks are very easy to create and evaluate in Python with Keras, but you must follow a strict model life-cycle.\n",
        "\n",
        "In this notebook you will discover the step-by-step life-cycle for creating, training, and evaluating Long Short-Term Memory (LSTM) Recurrent Neural Networks in Keras and how to make predictions with a trained model.\n",
        "\n",
        "overview of the 5 steps in the LSTM model life-cycle in Keras that we are going to look at.\n",
        "\n",
        "**Define Network**\n",
        "\n",
        "**Compile Network**\n",
        "\n",
        "**Fit Network**\n",
        "\n",
        "**Evaluate Network**\n",
        "\n",
        "**Make Predictions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jVBfdZzUni-"
      },
      "source": [
        "**Environment**\n",
        "This tutorial assumes you have a Python SciPy environment installed. You can use either Python 2 or 3 with this example.\n",
        "\n",
        "**step-1 Define Network**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7OX3iP8VTh_"
      },
      "source": [
        "Neural networks are defined in Keras as a sequence of layers. The container for these layers is the Sequential class. \n",
        "\n",
        "The first step is to create an instance of the Sequential class. Then you can create your layers and add them in the order that they should be connected. The LSTM recurrent layer comprised of memory units is called LSTM(). A fully connected layer that often follows LSTM layers and is used for outputting a prediction is called Dense().\n",
        "\n",
        "For example, we can do this in two steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlTr3zgmTsMS"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(2))\n",
        "model.add(Dense(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcdPYUBLWp_s"
      },
      "source": [
        "But we can also do this in one step by creating an array of layers and passing it to the constructor of the Sequential."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMzG1VG8WrSS"
      },
      "source": [
        "layers = [LSTM(2), Dense(1)]\n",
        "model = Sequential(layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-VIWdaMXY4-"
      },
      "source": [
        "Assuming your data is loaded as a NumPy array, you can convert a 2D dataset to a 3D dataset using the reshape() function in NumPy. If you would like columns to become timesteps for one feature, you can use:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nqpMwHtWuk2"
      },
      "source": [
        "data = data.reshape((data.shape[0], data.shape[1], 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-PppXH-XdJv"
      },
      "source": [
        "If you would like columns in your 2D data to become features with one timestep, you can use:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQy8qjbzZU4a"
      },
      "source": [
        "data = data.reshape((data.shape[0], 1, data.shape[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5ljZr0FZbLY"
      },
      "source": [
        "You can specify the input_shape argument that expects a tuple containing the number of timesteps and the number of features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WyQxuHoZwCz"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(5, input_shape=(2,1)))\n",
        "model.add(Dense(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQWldZKpZ4b9"
      },
      "source": [
        "LSTM layers can be stacked by adding them to the Sequential model. Importantly, when stacking LSTM layers, we must output a sequence rather than a single value for each input so that the subsequent LSTM layer can have the required 3D input. We can do this by setting the return_sequences argument to True. For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_cxzfMZaJre"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(5, input_shape=(2,1), return_sequences=True))\n",
        "model.add(LSTM(5))\n",
        "model.add(Dense(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMo-3Y1Laa1D"
      },
      "source": [
        "For example, activation functions that transform a summed signal from each neuron in a layer can be extracted and added to the Sequential as a layer-like object called Activation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmrohv_zajug"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(5, input_shape=(2,1)))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFehL9DUbLcH"
      },
      "source": [
        "**Step 2. Compile Network**\n",
        "\n",
        "Compilation is an efficiency step. It transforms the simple sequence of layers that we defined into a highly efficient series of matrix transforms in a format intended to be executed on your GPU or CPU, depending on how Keras is configured.\n",
        "\n",
        "Compilation requires a number of parameters to be specified, specifically tailored to training your network. Specifically, the optimization algorithm to use to train the network and the loss function used to evaluate the network that is minimized by the optimization algorithm.\n",
        "\n",
        "For example, below is a case of compiling a defined model and specifying the stochastic gradient descent (sgd) optimization algorithm and the mean squared error (mean_squared_error) loss function, intended for a regression type problem.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkHWCTJaOtsT"
      },
      "source": [
        "model.compile(optimizer='sgd', loss='mean_squared_error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6s4PZARbO0He"
      },
      "source": [
        "Alternately, the optimizer can be created and configured before being provided as an argument to the compilation step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrjt_aOtPGSk"
      },
      "source": [
        "algorithm = SGD(lr=0.1, momentum=0.3)\n",
        "model.compile(optimizer=algorithm, loss='mean_squared_error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQlSJhGGRa_Y"
      },
      "source": [
        "**step- 3 Fit Network**\n",
        "\n",
        "Once the network is compiled, it can be fit, which means adapt the weights on a training dataset. Fitting the network requires the training data to be specified, both a matrix of input patterns, X, and an array of matching output patterns, y. \n",
        "\n",
        "The network is trained using the backpropagation algorithm and optimized according to the optimization algorithm and loss function specified when compiling the model. The backpropagation algorithm requires that the network be trained for a specified number of epochs or exposures to the training dataset.\n",
        "\n",
        "Training can take a long time, from seconds to hours to days depending on the size of the network and the size of the training data.\n",
        "\n",
        "You can reduce the amount of information displayed to just the loss each epoch by setting the verbose argument to 2. You can turn off all output by setting verbose to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjT7w1xHPKg3"
      },
      "source": [
        "history = model.fit(X, y, batch_size=10, epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpyZA-r4q_UJ"
      },
      "source": [
        "history = model.fit(X, y, batch_size=10, epochs=100, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bF4e0TYFp0cq"
      },
      "source": [
        "**Step 4. Evaluate Network**\n",
        "\n",
        "Once the network is trained, it can be evaluated. The network can be evaluated on the training data, but this will not provide a useful indication of the performance of the network as a predictive model, as it has seen all of this data before. We can evaluate the performance of the network on a separate dataset, unseen during testing. This will provide an estimate of the performance of the network at making predictions for unseen data in the future.Once the network is trained, it can be evaluated.\n",
        "\n",
        "The model evaluates the loss across all of the test patterns, as well as any other metrics specified when the model was compiled, like classification accuracy. A list of evaluation metrics is returned.\n",
        "\n",
        "For example, for a model compiled with the accuracy metric, we could evaluate it on a new dataset as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShQifPCKrrh_"
      },
      "source": [
        "loss, accuracy = model.evaluate(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lq8eqaL6rvDy"
      },
      "source": [
        "As with fitting the network, verbose output is provided to give an idea of the progress of evaluating the model. We can turn this off by setting the verbose argument to 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx8g6gK4r2Ky"
      },
      "source": [
        "loss, accuracy = model.evaluate(X, y, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1l7hePnvr8va"
      },
      "source": [
        "**Step 5. Make Predictions**\n",
        "\n",
        "Once we are satisfied with the performance of our fit model, we can use it to make predictions on new data. This is as easy as calling the predict() function on the model with an array of new input patterns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kraDVtvospun"
      },
      "source": [
        "predictions = model.predict(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqZhyUVAsrB6"
      },
      "source": [
        "Alternately, for classification problems, we can use the predict_classes() function that will automatically convert uncrisp predictions to crisp integer class values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDNMul72sy8E"
      },
      "source": [
        "predictions = model.predict_classes(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qahR4Lks27o"
      },
      "source": [
        "As with fitting and evaluating the network, verbose output is provided to given an idea of the progress of the model making predictions. We can turn this off by setting the verbose argument to 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNBgTmA8s7PL"
      },
      "source": [
        "predictions = model.predict(X, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWiH3sbKs9yv"
      },
      "source": [
        "**End-to-End Worked Example**\n",
        "\n",
        "Letâ€™s tie all of this together with a small worked example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcVFdj9qtLIj",
        "outputId": "5e2ca1a4-038e-4558-a758-78d9a3e4a69d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Example of LSTM to learn a sequence\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "# create sequence\n",
        "length = 10\n",
        "sequence = [i/float(length) for i in range(length)]\n",
        "print(sequence)\n",
        "# create X/y pairs\n",
        "df = DataFrame(sequence)\n",
        "df = concat([df.shift(1), df], axis=1)\n",
        "df.dropna(inplace=True)\n",
        "# convert to LSTM friendly format\n",
        "values = df.values\n",
        "X, y = values[:, 0], values[:, 1]\n",
        "X = X.reshape(len(X), 1, 1)\n",
        "# 1. define network\n",
        "model = Sequential()\n",
        "model.add(LSTM(10, input_shape=(1,1)))\n",
        "model.add(Dense(1))\n",
        "# 2. compile network\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "# 3. fit network\n",
        "history = model.fit(X, y, epochs=1000, batch_size=len(X), verbose=0)\n",
        "# 4. evaluate network\n",
        "loss = model.evaluate(X, y, verbose=0)\n",
        "print(loss)\n",
        "# 5. make predictions\n",
        "predictions = model.predict(X, verbose=0)\n",
        "print(predictions[:, 0])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
            "9.56310541369021e-05\n",
            "[0.12466948 0.20848265 0.29829723 0.3931416  0.4919188  0.5934638\n",
            " 0.69660336 0.8002115  0.90325487]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}